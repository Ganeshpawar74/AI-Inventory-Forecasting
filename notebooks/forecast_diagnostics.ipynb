{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5eb43376",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section 1: Imports and settings\n",
    "import os\n",
    "from pathlib import Path\n",
    "import logging\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "import math\n",
    "\n",
    "# Plotting style\n",
    "sns.set(style='whitegrid')\n",
    "plt.rcParams['figure.dpi'] = 150\n",
    "COLOR_PALETTE = sns.color_palette('tab10')\n",
    "\n",
    "# Logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s %(levelname)s: %(message)s')\n",
    "logger = logging.getLogger(__name__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58939a0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-21 15:07:16,748 INFO: Loading dataset and models\n",
      "2025-12-21 15:07:24,469 INFO: Data shape: (300441, 36) (loaded from c:\\Users\\gp123\\Desktop\\Dummy\\Retail Store\\data\\ml_dataset_sample.csv)\n"
     ]
    }
   ],
   "source": [
    "# Section 2: Load dataset and models (robust path resolution)\n",
    "from pathlib import Path\n",
    "\n",
    "def find_file(name):\n",
    "    p = Path(name)\n",
    "    if p.exists():\n",
    "        return p\n",
    "    cwd = Path.cwd()\n",
    "    # search up to 4 directory levels\n",
    "    for parent in [cwd] + list(cwd.parents)[:4]:\n",
    "        candidate = parent / name\n",
    "        if candidate.exists():\n",
    "            return candidate\n",
    "    # fallback to rglob search in workspace root\n",
    "    for parent in [cwd] + list(cwd.parents)[:4]:\n",
    "        found = list(parent.rglob(name))\n",
    "        if found:\n",
    "            return found[0]\n",
    "    raise FileNotFoundError(name)\n",
    "\n",
    "DATA_PATH = find_file('data/ml_dataset_sample.csv')\n",
    "MODEL_PERCAT = find_file('models/future_14d_sum_percat_models.joblib')\n",
    "MODEL_GLOBAL = find_file('models/future_14d_sum_global_model.joblib')\n",
    "OUT_DIR = Path('reports/forecast_diagnostics')\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "logger.info('Loading dataset and models')\n",
    "df = pd.read_csv(DATA_PATH, parse_dates=['date'])\n",
    "models_percat = joblib.load(MODEL_PERCAT)\n",
    "model_global = joblib.load(MODEL_GLOBAL)\n",
    "\n",
    "# Validate target\n",
    "if 'future_14d_sum' not in df.columns:\n",
    "    raise AssertionError('Target future_14d_sum missing from dataset')\n",
    "\n",
    "logger.info('Data shape: %s (loaded from %s)', df.shape, DATA_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ebcf1fc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-21 15:07:40,624 INFO: Test rows: 36990, date range 2024-07-05 - 2024-10-02\n"
     ]
    }
   ],
   "source": [
    "# Section 3: Prepare test set (last 90 days, cutoff = 2024-10-02)\n",
    "CUTOFF = pd.to_datetime('2024-10-02')\n",
    "TEST_START = CUTOFF - pd.Timedelta(days=89)\n",
    "\n",
    "df_test = df[(df['date'] >= TEST_START) & (df['date'] <= CUTOFF)].copy()\n",
    "df_test = df_test.sort_values(['category','date']).reset_index(drop=True)\n",
    "\n",
    "# unify promo column if present\n",
    "promo_candidates = [c for c in df_test.columns if 'promo' in c.lower() or 'is_promo' in c.lower()]\n",
    "if 'promo_flag' in df_test.columns:\n",
    "    df_test['is_promo'] = df_test['promo_flag'].astype(int)\n",
    "elif promo_candidates:\n",
    "    df_test['is_promo'] = df_test[promo_candidates[0]].astype(int)\n",
    "else:\n",
    "    df_test['is_promo'] = 0\n",
    "\n",
    "logger.info('Test rows: %d, date range %s - %s', len(df_test), TEST_START.date(), CUTOFF.date())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "716db7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section 4: Utility functions\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def mae(y, yhat):\n",
    "    return mean_absolute_error(y, yhat)\n",
    "\n",
    "def rmse(y, yhat):\n",
    "    return math.sqrt(mean_squared_error(y, yhat))\n",
    "\n",
    "def r2(y, yhat):\n",
    "    return r2_score(y, yhat)\n",
    "\n",
    "\n",
    "def rolling_metrics_by_date(df_cat, col_actual='future_14d_sum', col_pred='pred'):\n",
    "    # compute per-date MAE and RMSE across series in the category\n",
    "    daily = df_cat.groupby('date').apply(lambda d: pd.Series({\n",
    "        'mae': mae(d[col_actual], d[col_pred]),\n",
    "        'rmse': rmse(d[col_actual], d[col_pred])\n",
    "    })).reset_index()\n",
    "    daily = daily.sort_values('date')\n",
    "    daily['mae_14d'] = daily['mae'].rolling(14, min_periods=1).mean()\n",
    "    daily['mae_30d'] = daily['mae'].rolling(30, min_periods=1).mean()\n",
    "    daily['rmse_14d'] = daily['rmse'].rolling(14, min_periods=1).mean()\n",
    "    daily['rmse_30d'] = daily['rmse'].rolling(30, min_periods=1).mean()\n",
    "    return daily\n",
    "\n",
    "\n",
    "def ensure_dir(path):\n",
    "    Path(path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "def save_fig(fig, path):\n",
    "    ensure_dir(Path(path).parent)\n",
    "    fig.savefig(path, bbox_inches='tight')\n",
    "    plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ed16f15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-21 15:08:00,528 INFO: Generating predictions\n",
      "2025-12-21 15:08:01,467 INFO: Predictions generated. Sample:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        date   category  future_14d_sum  pred_percat  pred_global\n",
      "0 2024-07-05  Beverages            35.0    34.372059     5.504692\n",
      "1 2024-07-05  Beverages            50.0    45.348040    11.248193\n",
      "2 2024-07-05  Beverages            19.0    19.092280     7.548225\n",
      "3 2024-07-05  Beverages            30.0    31.890552     9.371780\n",
      "4 2024-07-05  Beverages            50.0    52.386430     5.286014\n"
     ]
    }
   ],
   "source": [
    "# Section 5: Generate predictions per-category and global\n",
    "logger.info('Generating predictions')\n",
    "\n",
    "# Prepare container\n",
    "df_test['pred_percat'] = np.nan\n",
    "\n",
    "# models_percat: dict with key=category -> {'model':model,'features':features}\n",
    "for cat, info in models_percat.items():\n",
    "    try:\n",
    "        model = info['model'] if isinstance(info, dict) and 'model' in info else info\n",
    "        feat = info['features'] if isinstance(info, dict) and 'features' in info else None\n",
    "        mask = df_test['category'] == cat\n",
    "        if mask.sum() == 0:\n",
    "            continue\n",
    "        X = df_test.loc[mask, feat] if feat is not None else df_test.loc[mask].drop(columns=['future_14d_sum'], errors='ignore')\n",
    "        X = X.fillna(-1)\n",
    "        yhat_log = model.predict(X)\n",
    "        # model may be a raw LightGBM booster or sklearn wrapper; assume log1p training\n",
    "        yhat = np.expm1(yhat_log)\n",
    "        yhat = np.clip(yhat, 0, None)\n",
    "        df_test.loc[mask, 'pred_percat'] = yhat\n",
    "    except Exception as e:\n",
    "        logger.warning('Failed predict for %s: %s', cat, e)\n",
    "\n",
    "# Global predictions\n",
    "try:\n",
    "    Xg = df_test[models_percat[next(iter(models_percat))]['features']].fillna(-1)\n",
    "    # Rather than rely on features from one entry, compute features intersection\n",
    "    feature_set = list(set.intersection(*[set(v['features']) for v in models_percat.values()]))\n",
    "    if len(feature_set) > 0:\n",
    "        Xg = df_test[feature_set].fillna(-1)\n",
    "    else:\n",
    "        Xg = df_test.drop(columns=['future_14d_sum']).select_dtypes(include=[np.number]).fillna(-1)\n",
    "    yhatg_log = model_global.predict(Xg)\n",
    "    df_test['pred_global'] = np.expm1(yhatg_log)\n",
    "    df_test['pred_global'] = np.clip(df_test['pred_global'], 0, None)\n",
    "except Exception as e:\n",
    "    logger.error('Global prediction failed: %s', e)\n",
    "\n",
    "# Residuals\n",
    "df_test['resid_percat'] = df_test['future_14d_sum'] - df_test['pred_percat']\n",
    "df_test['resid_global'] = df_test['future_14d_sum'] - df_test['pred_global']\n",
    "\n",
    "logger.info('Predictions generated. Sample:')\n",
    "print(df_test[['date','category','future_14d_sum','pred_percat','pred_global']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "87a94ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section 6: Plot functions\n",
    "import matplotlib.dates as mdates\n",
    "from scipy.stats import skew, kurtosis\n",
    "\n",
    "\n",
    "def plot_actual_vs_pred(df_cat, category, outdir):\n",
    "    fig, ax = plt.subplots(figsize=(10,4))\n",
    "    ax.plot(df_cat['date'], df_cat['future_14d_sum'], label='Actual', color=COLOR_PALETTE[0])\n",
    "    ax.plot(df_cat['date'], df_cat['pred_percat'], label='Pred (per-cat)', color=COLOR_PALETTE[1])\n",
    "    ax.plot(df_cat['date'], df_cat['pred_global'], label='Pred (global)', color=COLOR_PALETTE[2], alpha=0.7)\n",
    "    # highlight promo days\n",
    "    promos = df_cat[df_cat['is_promo']==1]\n",
    "    if not promos.empty:\n",
    "        ax.scatter(promos['date'], promos['future_14d_sum'], marker='o', s=20, color='red', label='Promo')\n",
    "\n",
    "    ax.set_title(f'{category} — Actual vs Predicted (14d sum)')\n",
    "    ax.set_ylabel('Units (14d sum)')\n",
    "    ax.legend()\n",
    "    ax.xaxis.set_major_locator(mdates.WeekdayLocator(interval=2))\n",
    "    ax.xaxis.set_major_formatter(mdates.DateFormatter('%b %d'))\n",
    "    fname = outdir / 'actual_vs_pred.png'\n",
    "    save_fig(fig, fname)\n",
    "\n",
    "\n",
    "def plot_residuals(df_cat, category, outdir):\n",
    "    fig, axes = plt.subplots(1,2, figsize=(10,4))\n",
    "    sns.histplot(df_cat['resid_percat'].dropna(), kde=True, ax=axes[0], color=COLOR_PALETTE[3])\n",
    "    axes[0].axvline(0, color='k', linestyle='--')\n",
    "    axes[0].set_title('Residuals (per-cat): histogram + KDE')\n",
    "\n",
    "    axes[1].scatter(df_cat['pred_percat'], df_cat['resid_percat'], alpha=0.6)\n",
    "    axes[1].axhline(0, color='k', linestyle='--')\n",
    "    sns.regplot(x='pred_percat', y='resid_percat', data=df_cat, scatter=False, lowess=True, ax=axes[1], color='orange')\n",
    "    axes[1].set_xlabel('Predicted')\n",
    "    axes[1].set_ylabel('Residual (Actual - Pred)')\n",
    "    axes[1].set_title('Residual vs Predicted')\n",
    "\n",
    "    # annotations\n",
    "    sk = skew(df_cat['resid_percat'].dropna())\n",
    "    kt = kurtosis(df_cat['resid_percat'].dropna())\n",
    "    axes[0].text(0.95, 0.95, f'skew={sk:.2f}\\nkurt={kt:.2f}', transform=axes[0].transAxes, ha='right', va='top')\n",
    "\n",
    "    fname = outdir / 'residuals_hist_kde.png'\n",
    "    save_fig(fig, fname)\n",
    "\n",
    "\n",
    "def plot_rolling_errors(df_cat, category, outdir):\n",
    "    rolling = rolling_metrics_by_date(df_cat, col_actual='future_14d_sum', col_pred='pred_percat')\n",
    "    fig, ax = plt.subplots(figsize=(10,4))\n",
    "    ax.plot(rolling['date'], rolling['mae_14d'], label='MAE (14d)')\n",
    "    ax.plot(rolling['date'], rolling['mae_30d'], label='MAE (30d)')\n",
    "    ax.plot(rolling['date'], rolling['rmse_14d'], label='RMSE (14d)', linestyle='--')\n",
    "    ax.plot(rolling['date'], rolling['rmse_30d'], label='RMSE (30d)', linestyle='--')\n",
    "    ax.set_title(f'{category} — Rolling Errors')\n",
    "    ax.legend()\n",
    "    fname = outdir / 'rolling_errors.png'\n",
    "    save_fig(fig, fname)\n",
    "\n",
    "\n",
    "def plot_scatter_actual_vs_pred(df_cat, category, outdir):\n",
    "    fig, ax = plt.subplots(figsize=(6,6))\n",
    "    ax.scatter(df_cat['future_14d_sum'], df_cat['pred_percat'], alpha=0.4)\n",
    "    maxv = max(df_cat['future_14d_sum'].max(), df_cat['pred_percat'].max())\n",
    "    ax.plot([0,maxv],[0,maxv], color='k', linestyle='--')\n",
    "    mae_v = mae(df_cat['future_14d_sum'], df_cat['pred_percat'])\n",
    "    rmse_v = rmse(df_cat['future_14d_sum'], df_cat['pred_percat'])\n",
    "    r2_v = r2(df_cat['future_14d_sum'], df_cat['pred_percat'])\n",
    "    ax.set_title(f'{category} — Actual vs Pred (per-cat)\\nMAE={mae_v:.2f}, RMSE={rmse_v:.2f}, R2={r2_v:.3f}')\n",
    "    ax.set_xlabel('Actual')\n",
    "    ax.set_ylabel('Predicted')\n",
    "    fname = outdir / 'scatter_actual_vs_pred.png'\n",
    "    save_fig(fig, fname)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a538ecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-21 15:08:20,901 INFO: Processing category: Beverages\n",
      "C:\\Users\\gp123\\AppData\\Local\\Temp\\ipykernel_10188\\3656551388.py:16: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  daily = df_cat.groupby('date').apply(lambda d: pd.Series({\n",
      "2025-12-21 15:08:29,841 INFO: Processing category: Dairy\n",
      "C:\\Users\\gp123\\AppData\\Local\\Temp\\ipykernel_10188\\3656551388.py:16: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  daily = df_cat.groupby('date').apply(lambda d: pd.Series({\n",
      "2025-12-21 15:08:39,507 INFO: Processing category: Frozen\n",
      "C:\\Users\\gp123\\AppData\\Local\\Temp\\ipykernel_10188\\3656551388.py:16: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  daily = df_cat.groupby('date').apply(lambda d: pd.Series({\n",
      "2025-12-21 15:08:47,589 INFO: Processing category: Household\n",
      "C:\\Users\\gp123\\AppData\\Local\\Temp\\ipykernel_10188\\3656551388.py:16: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  daily = df_cat.groupby('date').apply(lambda d: pd.Series({\n",
      "2025-12-21 15:08:55,050 INFO: Processing category: Produce\n",
      "C:\\Users\\gp123\\AppData\\Local\\Temp\\ipykernel_10188\\3656551388.py:16: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  daily = df_cat.groupby('date').apply(lambda d: pd.Series({\n",
      "2025-12-21 15:09:04,788 INFO: Processing category: Snacks\n",
      "C:\\Users\\gp123\\AppData\\Local\\Temp\\ipykernel_10188\\3656551388.py:16: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  daily = df_cat.groupby('date').apply(lambda d: pd.Series({\n",
      "2025-12-21 15:09:11,730 INFO: Processing category: Stationery\n",
      "C:\\Users\\gp123\\AppData\\Local\\Temp\\ipykernel_10188\\3656551388.py:16: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  daily = df_cat.groupby('date').apply(lambda d: pd.Series({\n",
      "2025-12-21 15:09:17,931 INFO: Saved summary to reports\\forecast_diagnostics\\error_summary.csv\n"
     ]
    }
   ],
   "source": [
    "# Section 7: Driver - iterate categories and save plots & metrics\n",
    "categories = sorted(df_test['category'].unique())\n",
    "summary_rows = []\n",
    "\n",
    "for cat in categories:\n",
    "    logger.info('Processing category: %s', cat)\n",
    "    outdir = OUT_DIR / cat.replace(' ','_')\n",
    "    ensure_dir(outdir)\n",
    "    df_cat = df_test[df_test['category']==cat].copy()\n",
    "\n",
    "    # ensure predictions exist\n",
    "    if df_cat['pred_percat'].isna().all():\n",
    "        logger.warning('No per-category predictions for %s, skipping plots', cat)\n",
    "        continue\n",
    "\n",
    "    # plots\n",
    "    plot_actual_vs_pred(df_cat, cat, outdir)\n",
    "    plot_residuals(df_cat, cat, outdir)\n",
    "    plot_rolling_errors(df_cat, cat, outdir)\n",
    "    plot_scatter_actual_vs_pred(df_cat, cat, outdir)\n",
    "\n",
    "    # metrics for summary\n",
    "    mae_v = mae(df_cat['future_14d_sum'], df_cat['pred_percat'])\n",
    "    rmse_v = rmse(df_cat['future_14d_sum'], df_cat['pred_percat'])\n",
    "    r2_v = r2(df_cat['future_14d_sum'], df_cat['pred_percat'])\n",
    "    mean_bias = (df_cat['future_14d_sum'] - df_cat['pred_percat']).mean()\n",
    "    median_bias = (df_cat['future_14d_sum'] - df_cat['pred_percat']).median()\n",
    "    pct_under = (df_cat['resid_percat'] < 0).mean()\n",
    "\n",
    "    summary_rows.append({\n",
    "        'category':cat,\n",
    "        'model':'percat',\n",
    "        'MAE':mae_v,\n",
    "        'RMSE':rmse_v,\n",
    "        'R2':r2_v,\n",
    "        'mean_bias':mean_bias,\n",
    "        'median_bias':median_bias,\n",
    "        'pct_under_pred':pct_under\n",
    "    })\n",
    "\n",
    "# Global metrics (apply to categories as group)\n",
    "for cat in categories:\n",
    "    df_cat = df_test[df_test['category']==cat].copy()\n",
    "    mae_v = mae(df_cat['future_14d_sum'], df_cat['pred_global'])\n",
    "    rmse_v = rmse(df_cat['future_14d_sum'], df_cat['pred_global'])\n",
    "    r2_v = r2(df_cat['future_14d_sum'], df_cat['pred_global'])\n",
    "    mean_bias = (df_cat['future_14d_sum'] - df_cat['pred_global']).mean()\n",
    "    median_bias = (df_cat['future_14d_sum'] - df_cat['pred_global']).median()\n",
    "    pct_under = (df_cat['resid_global'] < 0).mean()\n",
    "    summary_rows.append({\n",
    "        'category':cat,\n",
    "        'model':'global',\n",
    "        'MAE':mae_v,\n",
    "        'RMSE':rmse_v,\n",
    "        'R2':r2_v,\n",
    "        'mean_bias':mean_bias,\n",
    "        'median_bias':median_bias,\n",
    "        'pct_under_pred':pct_under\n",
    "    })\n",
    "\n",
    "# Save summary\n",
    "df_summary = pd.DataFrame(summary_rows)\n",
    "summary_path = OUT_DIR / 'error_summary.csv'\n",
    "df_summary.to_csv(summary_path, index=False)\n",
    "logger.info('Saved summary to %s', summary_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f747675f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-21 15:09:27,472 INFO: No categories flagged for persistent bias\n"
     ]
    }
   ],
   "source": [
    "# Section 8: Flagging categories with persistent bias and append annotations\n",
    "flagged = []\n",
    "for _, row in df_summary[df_summary['model']=='percat'].iterrows():\n",
    "    mean_bias = row['mean_bias']\n",
    "    mean_actual = df_test[df_test['category']==row['category']]['future_14d_sum'].mean()\n",
    "    if abs(mean_bias) > 0.10 * mean_actual:\n",
    "        flagged.append({'category':row['category'],'mean_bias':mean_bias,'mean_actual':mean_actual})\n",
    "\n",
    "if flagged:\n",
    "    logger.warning('Flagged categories with persistent bias (>10%% of mean actual): %s', [f['category'] for f in flagged])\n",
    "    # append a small text file\n",
    "    with open(OUT_DIR / 'flagged_categories.txt','w') as f:\n",
    "        for fcat in flagged:\n",
    "            f.write(f\"{fcat['category']}: mean_bias={fcat['mean_bias']:.2f}, mean_actual={fcat['mean_actual']:.2f}\\n\")\n",
    "else:\n",
    "    logger.info('No categories flagged for persistent bias')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72eb1416",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section 9: Run-all verification and quick inline sample\n",
    "# Verify expected files\n",
    "expected = [OUT_DIR / cat.replace(' ','_') / 'actual_vs_pred.png' for cat in categories]\n",
    "existing = [p for p in expected if p.exists()]\n",
    "logger.info('Produced %d/%d expected category plots', len(existing), len(expected))\n",
    "print('Summary CSV sample:')\n",
    "print(pd.read_csv(summary_path).head())\n",
    "\n",
    "print('\\nFlagged categories (if any):')\n",
    "if (OUT_DIR / 'flagged_categories.txt').exists():\n",
    "    print(open(OUT_DIR / 'flagged_categories.txt').read())\n",
    "else:\n",
    "    print('None')\n",
    "\n",
    "logger.info('Diagnostics finished')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
