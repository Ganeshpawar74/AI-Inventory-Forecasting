"""
Production Streamlit app: Inventory Forecasting & Automated Reordering

Features:
- Upload inventory CSV and auto-detect required columns (SKU, Category, Date, Sales, Current stock, Unit cost, Lead time)
- Load "best" models (per-category enhanced models from models/future14_enhanced_percat_models.joblib)
  with fallback to pooled global model (models/future_14d_sum_global_model.joblib)
- Predict 14-day demand per SKU and display Forecast Results table
- Compute Reorder Point (ROP), suggest orders (Reorder_Yes), and Expected_Cost
- UI: file upload, category filter, SKU search, summary metrics, CSV downloads

Notes:
- Forecast_14d is predicted 14-day demand per SKU using per-category model when available.
- ROP = expected_LT + z * sigma_LT where sigma_LT is derived from historical residuals when available; otherwise a conservative heuristic is used.
- Expected_Cost = suggested_qty * unit_cost.

"""

from pathlib import Path
import sys
ROOT = Path(__file__).resolve().parents[1]
if str(ROOT) not in sys.path:
    sys.path.insert(0, str(ROOT))

import io
import hashlib
import math
import json
import numpy as np
import pandas as pd
import streamlit as st
from scipy.stats import norm
import smtplib
import requests 
from email.message import EmailMessage
from typing import Tuple, Dict, Any

# Local helpers
from scripts.simulate_reorders import load_models, compute_residual_stats, DATA as DATA_SAMPLE

ROOT = Path(__file__).resolve().parents[1]
MODELS_DIR = ROOT / 'models'

st.set_page_config(page_title="Inventory Forecast & Reorder (Production)", layout='wide')
st.title("Inventory Forecasting & Automated Reordering")

# ----------------- Cached model loader -----------------
@st.cache_data
def load_models_cached():
    """Load per-category enhanced models and global fallback."""
    try:
        models, global_model = load_models()
        return models or {}, global_model
    except Exception:
        return {}, None

# ----------------- Safe prediction helper -----------------

def safe_predict(model, X):
    """Try several ways to call model.predict and raise helpful errors."""
    try:
        return model.predict(X)
    except Exception as e:
        # try attribute-based feature alignment
        try:
            fn = getattr(model, 'feature_name', None)
            fn2 = None
            if callable(fn):
                cols = [c for c in fn() if c in X.columns]
                if cols:
                    return model.predict(X[cols])
        except Exception:
            pass
        try:
            fn2 = getattr(model, 'feature_names_in_', None) or getattr(model, 'feature_names_in', None)
            if fn2 is not None:
                cols = [c for c in fn2 if c in X.columns]
                if cols:
                    return model.predict(X[cols])
        except Exception:
            pass
        # lightgbm relax
        try:
            return model.predict(X, predict_disable_shape_check=True)
        except Exception:
            raise RuntimeError(f"Model predict failed: {e}")


# ----------------- Email helpers -----------------

def generate_reorder_email(row: Dict[str, Any], from_email: str, company_name: str = 'Retail Store') -> Tuple[str, str]:
    """Return (subject, body) plain-text for a reorder email based on reorder row.

    Uses fields: product_id, store_id, suggested_order_qty, ROP, stock_position, Forecast_14d, lead_time_days.
    """
    pid = row.get('product_id')
    sid = row.get('store_id', '')
    qty = int(row.get('suggested_order_qty', 0) or 0)
    rop = row.get('ROP', 0.0)
    stock = row.get('stock_position', 0)
    forecast = row.get('Forecast_14d', 0.0)
    lead = int(row.get('lead_time_days', 0) or 0)
    supplier = row.get('supplier_name', '')

    subject = f"Reorder request: {pid} - {qty} units"

    body = (
        f"Hello {supplier or 'Supplier'},\n\n"
        f"We hope you're well. Please find below a reorder request generated by our inventory system for {company_name}.\n\n"
        f"Product ID: {pid}\n"
        f"Store ID: {sid}\n"
        f"Suggested quantity: {qty}\n"
        f"Current stock position: {stock}\n"
        f"14-day forecast: {forecast:.2f}\n"
        f"Reorder Point (ROP): {rop:.2f}\n"
        f"Lead time (days): {lead}\n\n"
        f"Please confirm availability and estimated delivery date.\n\n"
        f"Thanks,\n{company_name} Procurement Team"
    )
    return subject, body


def send_email_smtp(smtp_host: str, smtp_port: int, username: str, password: str, from_email: str, to_email: str, subject: str, body: str, use_tls: bool = True) -> None:
    msg = EmailMessage()
    msg['Subject'] = subject
    msg['From'] = from_email
    msg['To'] = to_email
    msg.set_content(body)

    if use_tls:
        server = smtplib.SMTP(smtp_host, smtp_port, timeout=20)
        server.starttls()
    else:
        server = smtplib.SMTP(smtp_host, smtp_port, timeout=20)
    try:
        if username and password:
            server.login(username, password)
        server.send_message(msg)
    finally:
        server.quit()



# ----------------- UI helpers -----------------

def make_mailto(email: str, name: str | None = None) -> str:
    """Return an HTML mailto anchor (safe for inclusion in a small HTML table).

    If email is empty or None, returns an empty string.
    If name is provided, the link text is the name, otherwise the email address.
    """
    if not email or pd.isna(email):
        return ''
    text = name if name else email
    # Simple escaping of quotes
    email = str(email).replace('"', '')
    text = str(text).replace('"', '')
    return f'<a href="mailto:{email}">{text}</a>'

# ----------------- Column detection -----------------

FAVOURITES = {
    'sku': ['product_id','sku','product','item_id','id'],
    'category': ['category','cat','dept','department'],
    'date': ['date','ds','day'],
    'sales': ['units_sold','sales','demand','quantity','qty'],
    'current_stock': ['current_on_hand','on_hand','current_stock','stock','inventory'],
    'unit_cost': ['unit_cost','cost','price'],
    'lead_time': ['lead_time_days','lead_time'],
    # supplier/vendor optional fields
    'supplier_name': ['supplier_name','vendor_name','supplier','vendor'],
    'supplier_email': ['supplier_email','vendor_email','email']
}


def detect_columns(df: pd.DataFrame):
    """Return mapping of detected columns for required fields. Null if not found."""
    cols = {c: None for c in FAVOURITES}
    lc = {col.lower(): col for col in df.columns}
    for key, names in FAVOURITES.items():
        for n in names:
            if n in df.columns:
                cols[key] = n
                break
            # case-insensitive
            if n.lower() in lc:
                cols[key] = lc[n.lower()]
                break
    return cols


def validate_columns(mapping: dict):
    """Ensure mandatory fields are present."""
    missing = []
    for req in ['sku','sales','lead_time']:
        if mapping.get(req) is None:
            missing.append(req)
    return missing

# ----------------- Forecast & reorder logic -----------------

@st.cache_data
def predict_14d_for_inventory(inv_df: pd.DataFrame, _models: dict, _global_model, hist_df=None):
    """Return DataFrame with Forecast_14d and pred_source.
    Uses per-category models when available, else global_model.
    """
    df = inv_df.copy()
    df['Forecast_14d'] = 0.0
    df['pred_source'] = 'none'

    # Group by category for model choice
    for cat, group in df.groupby('category'):
        model_info = _models.get(cat)
        if model_info:
            model = model_info['model'] if isinstance(model_info, dict) else model_info
            feat = model_info.get('features') if isinstance(model_info, dict) else None
            X = group.copy()
            if feat is not None:
                missing = [c for c in feat if c not in X.columns]
                if missing:
                    # can't use per-cat model if features missing
                    use_model = None
                else:
                    Xf = X[feat].fillna(-1)
                    try:
                        yhat = safe_predict(model, Xf)
                        try:
                            vals = np.expm1(yhat)
                        except Exception:
                            vals = yhat
                        df.loc[group.index, 'Forecast_14d'] = np.clip(vals, 0, None)
                        df.loc[group.index, 'pred_source'] = 'percat'
                        continue
                    except Exception:
                        use_model = None
            # fallback to global if per-cat failed
        # try global
        if _global_model is not None:
            Xg = group.select_dtypes(include=[np.number]).fillna(-1)
            try:
                yhatg = safe_predict(_global_model, Xg)
                try:
                    vals = np.expm1(yhatg)
                except Exception:
                    vals = yhatg
                df.loc[group.index, 'Forecast_14d'] = np.clip(vals, 0, None)
                df.loc[group.index, 'pred_source'] = 'global'
            except Exception:
                df.loc[group.index, 'Forecast_14d'] = 0.0
        else:
            df.loc[group.index, 'Forecast_14d'] = 0.0
    return df


def compute_reorder(df_preds: pd.DataFrame, hist_df: pd.DataFrame = None, service_level=0.9, safety_mult=1.0, reserved_col=None):
    """Compute ROP, suggested_qty, reorder flag, expected_cost.
    If historical residuals available, use them to calculate sigma_LT per SKU.
    Otherwise use a conservative heuristic (CV=0.25 of daily forecast).
    """
    df = df_preds.copy()
    # get residual stats if available
    resid_map = {}
    if hist_df is not None:
        try:
            stats = compute_residual_stats(hist_df, *load_models_cached())
            stats = stats.set_index(['product_id','store_id'])
            resid_map = stats['resid_14d_std'].to_dict()
        except Exception:
            resid_map = {}

    z = float(norm.ppf(service_level)) * float(safety_mult)

    rows = []
    for _, r in df.iterrows():
        pid = r.get('product_id')
        sid = r.get('store_id') if 'store_id' in r.index else None
        forecast_14d = float(r.get('Forecast_14d', 0.0) or 0.0)
        lead = int(r.get('lead_time_days') if not pd.isna(r.get('lead_time_days')) else r.get('lead_time', 7))
        pred_daily = forecast_14d / 14.0
        expected_LT = pred_daily * lead

        # Sigma over lead time
        std14 = resid_map.get((pid, sid), 0.0)
        if std14 and std14 > 0:
            std_daily = std14 / math.sqrt(14)
            sigma_LT = std_daily * math.sqrt(lead)
        else:
            # heuristic: CV of 0.25 of daily forecast scaled by sqrt(lead)
            sigma_LT = (pred_daily * 0.25) * math.sqrt(lead)

        safety_stock = z * sigma_LT
        ROP = expected_LT + safety_stock

        # stock position
        current = int(r.get('current_on_hand', 0)) if not pd.isna(r.get('current_on_hand', 0)) else 0
        on_order = int(r.get('on_order', 0)) if 'on_order' in r.index and not pd.isna(r.get('on_order',0)) else 0
        reserved = int(r.get(reserved_col, 0)) if (reserved_col and r.get(reserved_col) is not None and not pd.isna(r.get(reserved_col))) else 0
        stock_position = current + on_order - reserved

        suggested_qty = max(0, int(math.ceil(ROP - stock_position)))
        reorder_yes = suggested_qty > 0
        unit_cost = float(r.get('unit_cost', 0.0) or 0.0)
        expected_cost = suggested_qty * unit_cost

        rows.append({
            'product_id': pid,
            'store_id': sid,
            'category': r.get('category',''),
            'Forecast_14d': forecast_14d,
            'pred_source': r.get('pred_source',''),
            'lead_time_days': lead,
            'pred_daily': pred_daily,
            'expected_LT': expected_LT,
            'sigma_LT': sigma_LT,
            'safety_stock': safety_stock,
            'ROP': ROP,
            'current_on_hand': current,
            'on_order': on_order,
            'reserved': reserved,
            'stock_position': stock_position,
            'suggested_order_qty': suggested_qty,
            'reorder_yes': reorder_yes,
            'unit_cost': unit_cost,
            'expected_cost': expected_cost,
            # supplier info (optional)
            'supplier_name': r.get('supplier_name','') if 'supplier_name' in r.index else '',
            'supplier_email': r.get('supplier_email','') if 'supplier_email' in r.index else ''
        })
    return pd.DataFrame(rows)

# ----------------- UI -----------------

with st.sidebar:
    st.header('Simulation / Forecast controls')
    service_level = st.selectbox('Service level', options=[0.9,0.95], index=0, format_func=lambda x: f"{int(x*100)}%")
    safety_mult = st.slider('Safety multiplier', 0.5, 2.0, 1.0, 0.05)
    reserved_col = st.text_input('Reserved column name (optional)', value='reserved')
    use_models = st.checkbox('Use trained models (per-cat preferred)', value=True)

st.sidebar.markdown('---')
st.sidebar.header('Upload')
uploaded = st.sidebar.file_uploader('Upload inventory CSV', type=['csv'])

# Load default sample if nothing uploaded
if uploaded is None:
    st.info('No inventory uploaded — using a small sample derived from data (for demo). Upload your inventory CSV to analyze your SKUs.')
    try:
        inv = pd.read_csv(DATA_SAMPLE)
        # derive a minimal inventory snapshot
        inv = inv.groupby(['product_id','store_id','lead_time_days','category'], as_index=False).agg({'units_sold':'sum'})
        inv = inv.rename(columns={'units_sold':'historical_units_sold'})
        inv['current_on_hand'] = 0
        inv['on_order'] = 0
    except Exception:
        st.stop()
else:
    try:
        inv = pd.read_csv(uploaded)
    except Exception as e:
        st.error(f'Failed to read uploaded CSV: {e}')
        st.stop()

st.write('Detected columns and validation:')
col_map = detect_columns(inv)
st.json(col_map)
missing = validate_columns(col_map)
if missing:
    st.error(f'Missing required columns in uploaded data: {missing} — please include at least SKU (product_id), Sales (units_sold), and Lead Time (lead_time_days)')
    st.stop()

# Normalize column usage: rename detected names to canonical names
inv = inv.rename(columns={col_map['sku']:'product_id'}) if col_map['sku'] and col_map['sku']!='product_id' else inv
if col_map['category'] and col_map['category'] != 'category':
    inv = inv.rename(columns={col_map['category']:'category'})
if col_map['lead_time'] and col_map['lead_time'] != 'lead_time_days':
    inv = inv.rename(columns={col_map['lead_time']:'lead_time_days'})
# sales -> we don't strictly need per-row historical sales here, but keep as reference
if col_map['sales'] and col_map['sales'] != 'units_sold':
    inv = inv.rename(columns={col_map['sales']:'units_sold'})
if col_map['current_stock'] and col_map['current_stock'] != 'current_on_hand':
    inv = inv.rename(columns={col_map['current_stock']:'current_on_hand'})
if col_map['unit_cost'] and col_map['unit_cost'] != 'unit_cost':
    inv = inv.rename(columns={col_map['unit_cost']:'unit_cost'})

# Normalize supplier fields if present
if col_map.get('supplier_name') and col_map['supplier_name'] != 'supplier_name':
    inv = inv.rename(columns={col_map['supplier_name']:'supplier_name'})
if col_map.get('supplier_email') and col_map['supplier_email'] != 'supplier_email':
    inv = inv.rename(columns={col_map['supplier_email']:'supplier_email'})

# Ensure required columns exist in normalized names
for c in ['product_id','lead_time_days']:
    if c not in inv.columns:
        inv[c] = np.nan
if 'category' not in inv.columns:
    inv['category'] = ''
if 'current_on_hand' not in inv.columns:
    inv['current_on_hand'] = 0
if 'unit_cost' not in inv.columns:
    inv['unit_cost'] = 0.0
# Ensure supplier columns exist (optional)
if 'supplier_name' not in inv.columns:
    inv['supplier_name'] = ''
if 'supplier_email' not in inv.columns:
    inv['supplier_email'] = ''

# Load models
models, global_model = load_models_cached() if use_models else ({}, None)

st.markdown('---')
# Filters and quick controls
cols_left, cols_right = st.columns([3,1])
with cols_left:
    cats = ['All'] + sorted(inv['category'].dropna().astype(str).unique().tolist())
    sel_cat = st.multiselect('Filter: Category', options=cats, default=['All'])
    sku_q = st.text_input('SKU search (product_id substring)')
with cols_right:
    st.write('Model selection:')
    st.write('Per-cat models loaded:', len(models))
    st.write('Global model present:', bool(global_model))

# Filter data
df_view = inv.copy()
if 'All' not in sel_cat:
    df_view = df_view[df_view['category'].isin(sel_cat)]
if sku_q:
    df_view = df_view[df_view['product_id'].astype(str).str.contains(sku_q, case=False, na=False)]

st.subheader('Inventory snapshot (sample)')
st.dataframe(df_view.head(200))

# Predictions
with st.spinner('Running forecasts...'):
    preds = predict_14d_for_inventory(df_view, models if use_models else {}, global_model if use_models else None)

st.header('Forecast Results')
forecast_cols = ['product_id','store_id','category','Forecast_14d','pred_source']
st.dataframe(preds[forecast_cols].sort_values('Forecast_14d', ascending=False).reset_index(drop=True))
try:
    csv_out = preds[forecast_cols].to_csv(index=False).encode('utf-8')
    st.download_button('Download Forecasts CSV', data=csv_out, file_name='forecasts.csv')
except Exception:
    pass

# Compute reorder suggestions using historical sample if available
hist_df = None
try:
    hist_df = pd.read_csv(DATA_SAMPLE, parse_dates=['date'])
except Exception:
    hist_df = None

with st.spinner('Computing reorder suggestions...'):
    reorder_df = compute_reorder(preds, hist_df=hist_df, service_level=service_level, safety_mult=safety_mult, reserved_col=(reserved_col if reserved_col else None))


st.header('Reorder Recommendations')
reorder_cols = ['product_id','store_id','category','supplier_name','supplier_email','Forecast_14d','ROP','stock_position','suggested_order_qty','reorder_yes','unit_cost','expected_cost']
# Prepare display version with clickable mailto links (HTML). Keep CSV download with plain emails.
disp_df = reorder_df[reorder_cols].sort_values('suggested_order_qty', ascending=False).reset_index(drop=True)
# Create an HTML-safe copy
disp_html_df = disp_df.copy()
# Convert supplier columns to mailto links (supplier name links to email if email present)
if 'supplier_email' in disp_html_df.columns:
    disp_html_df['supplier_email'] = disp_html_df['supplier_email'].fillna('').apply(lambda e: make_mailto(e))
if 'supplier_name' in disp_html_df.columns and 'supplier_email' in disp_html_df.columns:
    def name_link(row):
        email = row.get('supplier_email', '')
        # If supplier_email already converted to HTML link, extract raw email if needed
        raw_email = ''
        if isinstance(row.get('supplier_email'), str) and 'mailto:' in str(row.get('supplier_email')):
            # crude extraction: href="mailto:EMAIL"
            part = str(row.get('supplier_email'))
            start = part.find('mailto:')
            if start >= 0:
                raw_email = part[start+7:part.find('"', start)] if '"' in part[start:] else part[start+7:]
        else:
            raw_email = row.get('supplier_email', '')
        if raw_email:
            return make_mailto(raw_email, row.get('supplier_name',''))
        return row.get('supplier_name','')
    disp_html_df['supplier_name'] = disp_html_df.apply(name_link, axis=1)

# Generate HTML table for display with unsafe HTML allowed
html = disp_html_df.to_html(escape=False, index=False)
st.markdown(html, unsafe_allow_html=True)

# CSV download keeps plain values
try:
    csv_out = disp_df.to_csv(index=False).encode('utf-8')
    st.download_button('Download Reorders CSV', data=csv_out, file_name='reorder_suggestions.csv')
except Exception:
    pass

# # Email Suppliers UI removed per request
# st.info('The "Email Suppliers for Reorders" UI has been removed from this app.')

# ----------------- n8n Webhook send -----------------

def send_reorders_to_n8n(webhook_url: str, rows: pd.DataFrame, batch: bool = True, headers: dict = None, timeout: int = 10):
    """Send reorder lines to an n8n webhook.
    If batch is True, sends a single POST with {'timestamp', 'reorders': [...] }.
    Otherwise sends one POST per row with {'timestamp', 'reorder': {...}}.
    Returns a list of report dicts with status_code and response text.
    """
    reports = []
    payload_rows = rows.to_dict(orient='records')
    ts = pd.Timestamp.utcnow().isoformat()
    headers = headers or {}
    try:
        if batch:
            payload = {'timestamp': ts, 'reorders': payload_rows}
            r = requests.post(webhook_url, json=payload, headers=headers, timeout=timeout)
            reports.append({'sent_count': len(payload_rows), 'webhook_url': webhook_url, 'status_code': r.status_code, 'response': r.text})
        else:
            for row in payload_rows:
                payload = {'timestamp': ts, 'reorder': row}
                try:
                    r = requests.post(webhook_url, json=payload, headers=headers, timeout=timeout)
                    reports.append({'product_id': row.get('product_id'), 'status_code': r.status_code, 'response': r.text})
                except Exception as e:
                    reports.append({'product_id': row.get('product_id'), 'status_code': None, 'response': str(e)})
    except Exception as e:
        reports.append({'sent_count': len(payload_rows), 'webhook_url': webhook_url, 'status_code': None, 'response': str(e)})
    return reports


# n8n webhook UI
st.markdown('---')
st.subheader('Send Reorders to n8n Webhook')
with st.expander('n8n webhook settings & send'):
    st.write('Configure the n8n webhook URL and send reorder lines (where `reorder_yes` is True).')
    webhook_url = st.text_input('n8n webhook URL', value='https://tempo08022.app.n8n.cloud/webhook-test/bed32d02-e2fc-4eb0-8c8a-b888db27fd30')
    batch_send = st.checkbox('Batch send (single request with all reorders)', value=True)
    headers_raw = st.text_area('Extra headers as JSON (optional)', value='{}', height=80)
    try:
        extra_headers = json.loads(headers_raw or '{}')
    except Exception:
        extra_headers = {}
        st.error('Headers JSON is invalid; using empty headers.')

    rows_to_send = reorder_df[reorder_df['reorder_yes']].copy()
    st.write(f'Rows ready to send: {len(rows_to_send)}')
    if len(rows_to_send) > 0:
        # preview payload
        preview_sample = rows_to_send.head(5).to_dict(orient='records')
        st.write('Preview (first 5 reorders):')
        st.json({'timestamp': pd.Timestamp.utcnow().isoformat(), 'reorders_preview': preview_sample})
    else:
        st.info('No suggested reorders to send')

    if st.button('Send reorders to n8n'):
        if not webhook_url:
            st.error('Please provide a webhook URL')
        elif rows_to_send.empty:
            st.warning('No reorder lines to send')
        else:
            st.info(f"Sending {len(rows_to_send)} reorder lines to n8n ({'batch' if batch_send else 'per-row'})...")
            try:
                reports = send_reorders_to_n8n(webhook_url, rows_to_send, batch=batch_send, headers=extra_headers)
                report_df = pd.DataFrame(reports)
                # NOTE: per request, do not persist n8n report CSV to disk; display results in-app only
                st.success('Requests completed; responses received')
                st.dataframe(report_df.head(50))
            except Exception as e:
                st.error(f'Failed to send to webhook: {e}')


# Summary KPIs
st.subheader('Summary Metrics')
col1, col2, col3 = st.columns(3)
col1.metric('Total SKUs', int(reorder_df['product_id'].nunique()))
col2.metric('Reorder Count', int(reorder_df['reorder_yes'].sum()))
col3.metric('Total Expected Cost', f"{reorder_df['expected_cost'].sum():.2f}")

# Per-category summary
st.subheader('Per-category summary')
cat_sum = reorder_df.groupby('category').agg(reorder_lines=('reorder_yes','sum'), total_qty=('suggested_order_qty','sum'), total_cost=('expected_cost','sum')).reset_index().sort_values('total_cost', ascending=False)
st.dataframe(cat_sum)

# Notes / explanation
st.markdown('''
**Notes:**
- Forecast uses per-category tuned models when available (`models/future14_enhanced_{category}.joblib`) and falls back to `models/future_14d_sum_global_model.joblib` when needed.
- Reorder Point (ROP) is computed as Expected_LT + z * sigma_LT. If historical residuals are unavailable, a conservative heuristic for sigma_LT is used (25% CV of daily forecast scaled by sqrt(lead time)).
- Expected_Cost = suggested_qty * unit_cost.
''')

st.success('Done')
